{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples of Multicore Applications:\n",
    "# Shared-Memory Multiprocess Applications\n",
    "In this notebook we look at multiprocess applications in IoTPy. The processes share memory. Associated with each process is an agent. The application can also have: \n",
    "<ol>\n",
    "    <li> source threads that acquire data from external sources and </li>\n",
    "    <li> actuator threads the get data from output queues. </li>\n",
    "</ol>\n",
    "<b> The central idea is that an application is specified by connecting outputs of processes to inputs of processes.</b>\n",
    "\n",
    "## The Agent associated with a Process\n",
    "A process in a multicore application executes an agent with the following signature:\n",
    "<br>\n",
    "<br>\n",
    "<b>f(in_streams, out_streams)</b>\n",
    "<br>\n",
    "<br>\n",
    "where:\n",
    "<ol>\n",
    "    <li> <i>f</i> is a function. </li>\n",
    "    <li> <i>in_streams</i> is a list of input streams. </li>\n",
    "    <li> <i>out_streams</i> is a list of output streams. </li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import threading\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from IoTPy.core.stream import Stream, StreamArray, run\n",
    "from IoTPy.agent_types.op import map_element, map_list, map_window\n",
    "from IoTPy.helper_functions.recent_values import recent_values\n",
    "from IoTPy.helper_functions.print_stream import print_stream\n",
    "\n",
    "from IoTPy.concurrency.multicore import get_processes, get_processes_and_procs\n",
    "from IoTPy.concurrency.multicore import terminate_stream\n",
    "from IoTPy.concurrency.multicore import get_proc_that_inputs_source\n",
    "from IoTPy.concurrency.multicore import extend_stream"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we show a collection of agents, <i>f</i>, <i>g</i>, <i>h</i>, and <i>r</i>, with this signature. We will use these agents in the examples of multicore programs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(in_streams, out_streams):\n",
    "    map_element(lambda v: v+100, in_streams[0], out_streams[0])\n",
    "\n",
    "def g(in_streams, out_streams):\n",
    "    s = Stream('s')\n",
    "    map_element(lambda v: v*2, in_streams[0], s)\n",
    "    print_stream(s, 's')\n",
    "\n",
    "def h(in_streams, out_streams):\n",
    "    map_element(lambda v: v*2, in_streams[0], out_streams[0])\n",
    "\n",
    "def r(in_streams, out_streams):\n",
    "    t = Stream('t')\n",
    "    map_element(lambda v: v*3, in_streams[0], t)\n",
    "    print_stream(t, 't')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Threads\n",
    "A process may execute an arbitrary number of threads. You can use any thread target. \n",
    "<br>\n",
    "<br>\n",
    "Most threads in IoTPY applications pass data to the application or get data from the application. A thread that passes data from an external source, such as a sensor or a Twitter stream, to an IoTPy process is called a <b>source thread</b>. \n",
    "### Source Threads\n",
    "A source thread calls the following function to put data into a stream:\n",
    "<br>\n",
    "<br>\n",
    "<b>extend_stream(procs, data, stream_name)</b>\n",
    "<br>\n",
    "<br>\n",
    "where\n",
    "<ol>\n",
    "    <li> <i>procs</i> is a list of process metadata created from the specification of a multicore program. <i>procs</i> is passed as a parameter to the thread target. We will discuss <i>procs</i> later. </li>\n",
    "    <li> <i>data</i> is a list or an array. </li>\n",
    "    <li> <i>stream_name</i> is a string which is the name of a stream.</li>\n",
    "</ol>\n",
    "In the example, <i>source_thread_target</i>, the function has a single argument <i>procs</i>. All thread targets that extend streams must have <i>procs</i> as one of its arguments.\n",
    "<br>\n",
    "<br>\n",
    "This function executes a loop in which puts specified data into a stream called <i>x</i> and then sleeps thus yielding the thread.\n",
    "<br>\n",
    "<br>\n",
    "<b>terminate_stream</b>\n",
    "\n",
    "### Sources\n",
    "A source in a multiprocess application is associated with a process. A source <i>s</i> in a process <i>p</i> is essentially an output stream of <i>p</i>; it differs from output streams created by <i>p</i> in the sense that it is fed by a thread rather than computed by <i>p</i>. However, we don't include <i>s</i> in the list of <b>outputs</b> of <i>p</i>; instead we include <i>s</i> in the list of <b>sources</b> of <i>p</i>.\n",
    "<br>\n",
    "<br>\n",
    "Note that a source thread that generates a source <i>s</i> in a process <i>p</i> can run in a different process <i>p'</i>. You want to choose the process in which to run a thread to balance the computational load across processes. If the output of a source <i>s</i> feeds input streams of exactly one process <i>r</i> then efficiency suggests that <i>s</i> should be a source of <i>r</i>; however, you can make <i>s</i> the source of any process.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps to create a multiprocess application\n",
    "You may find the following steps helpful in creating a multiprocess application. You don't have to follow exactly these steps in this order.\n",
    "<br>\n",
    "<br>\n",
    "<i>Step 0</i>: <b>Define agent functions and source thread targets.</b>\n",
    "<ol>\n",
    "        <li> <i>Step 0.0</i>: Each process has an agent associated with it, as described earlier. Specify the agent functions for each process. Recall that an agent function has the form:\n",
    "<br>\n",
    "            <b>f(in_streams, out_streams)</b>.</li>\n",
    "    <li><i>Step 0.1 </i> Define the thread targets for each source. These thread targets typically extend a source stream, and finally terminate the stream.</li>\n",
    "</ol>\n",
    "<i>Step 1: </i> <b>Give the multicore_specification of streams and processes.</b> The multicore specification specifies a list of streams and a list of agents.\n",
    "<br>\n",
    "<i>Step 2: </i> <b>Create processes</b> by calling:\n",
    "<br>\n",
    "processes, procs = get_processes_and_procs(multicore_specification)\n",
    "<br>\n",
    "<i>Step 3: </i> <b>Create threads</b> (if any). An example creation of a thread is:\n",
    "<br>\n",
    "thread_0 = threading.Thread(target=source_thread_target, args=(procs,))\n",
    "<br>\n",
    "<i>Step 4: </i> <b>Specify which process each thread runs in.</b> An example:\n",
    "<br>\n",
    "procs['p1'].threads = [thread_0]\n",
    "<br>\n",
    "<i>Step 5: </i>. <b>Start, join and terminate processes </b> by calling\n",
    "<br>\n",
    "for process in processes: process.start()\n",
    "for process in processes: process.join()\n",
    "for process in processes: process.terminate()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 0: Define source thread target (if any).\n",
    "# We will use this thread target for the next few examples.\n",
    "def source_thread_target(procs):\n",
    "    for i in range(3):\n",
    "        extend_stream(procs, data=list(range(i*2, (i+1)*2)), stream_name='x')\n",
    "        time.sleep(0.001)\n",
    "    terminate_stream(procs, stream_name='x')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple example of a multicore program\n",
    "![alt text](ExamplesOfSimpleMultipleProcess.jpg \"Simple MultiProcess\")\n",
    "\n",
    "### Multicore specification: Processes and their connecting streams\n",
    "Look at <b>multicore_specification</b>. The specification states that the program has two processes called p0 and p1. Process p0 has a single input stream <i>x</i> and a single output stream <i>y</i>. Process p1 has a single input stream <i>y</i> and no output streams. Thus, the output <i>y</i> of process p0 is the input of process p1.\n",
    "<br>\n",
    "### Multicore specification: Streams\n",
    "Streams are specified by a list of pairs where each pair is a stream name and a stream type. The stream type 'i' identifies integers, 'f' floats and 'd' double. We use stream types to allow processes to share memory in Python 2.7+. In this example, the pair ('x', 'i') says that the program has a stream <i>x</i> of type int.\n",
    "<br>\n",
    "### Multicore specification: Sources\n",
    "Process p0 has a <b>source_functions</b> called <i>h</i>. Function <i>h</i> executes in its own thread within process p0; this thread is started when the process is started. Function <i>h</i> has a single argument called <i>proc</i> which is a dummy argument that represents a process. \n",
    "<br>\n",
    "<br>\n",
    "Function <i>h</i> puts data into stream <i>x</i> when it executes <b>proc.copy_stream()</b>. The thread executing <i>h</i> then sleeps for 0.001 seconds before appending more data to stream <i>x</i>. Finally, the thread signals that the source has terminated appending data to stream <i>x</i> by calling <b>proc.finished_source('x')</b>.\n",
    "### Process Structure\n",
    "The source <i>h</i> outputs a stream <i>x</i> which is an input of process p0. The output <i>y</i> of process p0 is an input to process p1.\n",
    "### Process Computations\n",
    "The computation of a process is specified by a function with two arguments <i>in_streams</i> and <i>out_streams</i>. The computation carried out by p0 is specified by function <i>f</i> which reads a single input stream, <i>in_streams[0]</i> and write a single output stream, <i>out_streams[0]</i>. This agent makes:\n",
    "<br>\n",
    "<br>\n",
    "<b> y[n] = x[n] + 100 </b>\n",
    "<br>\n",
    "<br>\n",
    "The computation carried out by process p1 is specified by function <i>g</i> which prints <b>2 * y[n]</b> for all n.\n",
    "<br>\n",
    "<br>\n",
    "The source function <i>h</i> sets x[n] to n, and so this multicore process prints:\n",
    "<br>\n",
    "<br>\n",
    "<b> 2 * (n + 100) </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can't pickle local object 'MulticoreProcess.make_process.<locals>.target'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m procs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mp1\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mthreads \u001b[38;5;241m=\u001b[39m [thread_0]\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Step 5: Start, join and terminate processes.\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m process \u001b[38;5;129;01min\u001b[39;00m processes: process\u001b[38;5;241m.\u001b[39mstart()\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m process \u001b[38;5;129;01min\u001b[39;00m processes: process\u001b[38;5;241m.\u001b[39mjoin()\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m process \u001b[38;5;129;01min\u001b[39;00m processes: process\u001b[38;5;241m.\u001b[39mterminate()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _current_process\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemon\u001b[39m\u001b[38;5;124m'\u001b[39m), \\\n\u001b[1;32m    119\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemonic processes are not allowed to have children\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    120\u001b[0m _cleanup()\n\u001b[0;32m--> 121\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sentinel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen\u001b[38;5;241m.\u001b[39msentinel\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;66;03m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[0;32m--> 224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mProcess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/context.py:284\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpopen_spawn_posix\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Popen\n\u001b[0;32m--> 284\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/popen_spawn_posix.py:32\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, process_obj):\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fds \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 32\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/popen_fork.py:19\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinalizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_launch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/popen_spawn_posix.py:47\u001b[0m, in \u001b[0;36mPopen._launch\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     46\u001b[0m     reduction\u001b[38;5;241m.\u001b[39mdump(prep_data, fp)\n\u001b[0;32m---> 47\u001b[0m     \u001b[43mreduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     49\u001b[0m     set_spawning_popen(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[0;34m(obj, file, protocol)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdump\u001b[39m(obj, file, protocol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;124;03m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[0;32m---> 60\u001b[0m     \u001b[43mForkingPickler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: Can't pickle local object 'MulticoreProcess.make_process.<locals>.target'"
     ]
    }
   ],
   "source": [
    "# Step 1: multicore_specification of streams and processes.\n",
    "multicore_specification = [\n",
    "    # Streams\n",
    "    [('x', 'i'), ('y', 'i')],\n",
    "    # Processes\n",
    "    [{'name': 'p0', 'agent': f, 'inputs':['x'], 'outputs': ['y'], 'sources':['x']},\n",
    "     {'name': 'p1', 'agent': g, 'inputs': ['y']}]]\n",
    "\n",
    "# Step 2: Create processes.\n",
    "processes, procs = get_processes_and_procs(multicore_specification)\n",
    "\n",
    "# Step 3: Create threads (if any).\n",
    "thread_0 = threading.Thread(target=source_thread_target, args=(procs,))\n",
    "\n",
    "# Step 4: Specify which process each thread (if any) runs in.\n",
    "# thread_0 runs in the process called 'p1'\n",
    "procs['p1'].threads = [thread_0]\n",
    "\n",
    "# Step 5: Start, join and terminate processes.\n",
    "for process in processes: process.start()\n",
    "for process in processes: process.join()\n",
    "for process in processes: process.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: multicore_specification of streams and processes.\n",
    "multicore_specification = [\n",
    "    # Streams\n",
    "    [('x', 'i'), ('y', 'i')],\n",
    "    # Processes\n",
    "    [{'name': 'p0', 'agent': f, 'inputs':['x'], 'outputs': ['y']},\n",
    "     {'name': 'p1', 'agent': g, 'inputs': ['y'], 'sources':['x']}]]\n",
    "\n",
    "# Step 2: Create processes.\n",
    "processes, procs = get_processes_and_procs(multicore_specification)\n",
    "\n",
    "# Step 3: Create threads (if any).\n",
    "thread_0 = threading.Thread(target=source_thread_target, args=(procs,))\n",
    "\n",
    "# Step 4: Specify which process each thread (if any) runs in.\n",
    "# thread_0 runs in the process called 'p1'\n",
    "procs['p1'].threads = [thread_0]\n",
    "\n",
    "# Step 5: Start, join and terminate processes.\n",
    "for process in processes: process.start()\n",
    "for process in processes: process.join()\n",
    "for process in processes: process.terminate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of Three Processes in a Row\n",
    "![alt text](ThreeProcessesInARow.jpg \"Title\")\n",
    "This example is the same as the previous one except that it has a third process attached to process p2. The source thread <i>h</i> feeds stream <i>x</i> which is the input to process p0. The output of p0 is stream <i>y</i> which is the input to process p1. The output of p1 is stream <i>z</i> which is the input to process p2.\n",
    "<br>\n",
    "### Streams\n",
    "[('x', 'i'), ('y', 'i'), ('z', 'i')]\n",
    "This specifies that this system has three streams called 'x', 'y' and 'z' which contain ints.\n",
    "### Sources\n",
    "<b>Source Function</b> <i>h</i>\n",
    "<br>\n",
    "This function runs in its own thread. The function puts [0, 1, 2] into the stream called <i>x</i>, then sleeps, and then puts [3, 4, 5] into <i>x</i>. The function then calls <i>finished_source</i> to indicate that it has finished executing and so no further values will be appended to <i>x</i>.\n",
    "<br>\n",
    "<br>\n",
    "This function executes in a thread that runs in process <i>p0</i> because <i>h</i> appears in the specification for <i>p0</i>:\n",
    "<br>\n",
    "{'name': 'p0', 'agent': f, 'inputs':['x'], 'outputs': ['y'], 'sources': ['x'], <b>'source_functions':[h]</b>}\n",
    "<br>\n",
    "<b>Stream Sources</b> Stream <i>x</i> is a source in process <i>p0</i> because it appears in the specification of process <i>p0</i>.\n",
    "### Process Structure\n",
    "<ol>\n",
    "    <li>Source function <i>h</i> feeds stream <i>x</i> which is an input of process <i>p0</i>. </li>\n",
    "    <li> Output stream <i>y</i> of process <i>p0</i> is an input stream of process <i>p1</i>.</li>\n",
    "    <li> Output stream <i>z</i> of process <i>p1</i> is an input stream of process <i>p2</i>.</li>\n",
    "    <li> Process <i>p2</i> has no output streams. </li>\n",
    "</ol>\n",
    "\n",
    "### Process Functions\n",
    "Each process function has parameters <i>in_streams</i>, <i>out_streams</i> and possibly additional keyword or positional arguments. The process functions associated with processes <i>p0</i>, <i>p1</i>, and <i>p2</i> are <i>f</i>, <i>g</i> and <i>r</i>, respectively. The process function for a process is in the processes part of <i>multicore_specification</i>.\n",
    "<br>\n",
    "<ol>\n",
    "    <li> The source extends stream <i>x</i> with [0, 1, 2, 3, 4, 5] and then calls <i>finished_source</i>. Thus <b>x[n] = n </b> for n less than 6. </li>\n",
    "    <li> Process function <i>f</i> of <i>p0</i> adds 100 to its <i>in_streams[0]</i> which is stream <i>x</i> and puts the result in its <i>out_streams[0]</i> which is stream <i>y</i>. Thus <b>y[n] = x[n]+100 = n + 100 for </b> </li>.\n",
    "    <li> Process function <i>g</i> of <i>p1</i> multiplies 2 to its <i>in_streams[0]</i> which is stream <i>y</i> and puts the result in its <i>out_streams[0]</i> which is stream <i>z</i>. Thus <b>z[n] = 2*y[n] = 2n + 200 for </b> </li>.\n",
    "    <li> Process function <i>r</i> of <i>p2</i> creates a stream <i>s</i> and multiplies 3 to its <i>in_streams[0]</i> which is stream <i>z</i> and and puts the result stream <i>s</i>. This function also prints stream <i>s</i>. Thus it prints <b>3*z[n] = 6n + 600 for </b> </li>.\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: multicore_specification of streams and processes.\n",
    "multicore_specification = [\n",
    "    # Streams\n",
    "    [('x', 'i'), ('y', 'i'), ('z', 'i')],\n",
    "    # Processes\n",
    "    [{'name': 'p0', 'agent': f, 'inputs':['x'], 'outputs': ['y']},\n",
    "     {'name': 'p1', 'agent': h, 'inputs': ['y'], 'outputs': ['z'], 'sources': ['x']},\n",
    "     {'name': 'p2', 'agent': r, 'inputs': ['z']}]\n",
    "    ]\n",
    "\n",
    "# Step 2: Create processes.\n",
    "processes, procs = get_processes_and_procs(multicore_specification)\n",
    "\n",
    "# Step 3: Create threads (if any)\n",
    "thread_0 = threading.Thread(target=source_thread_target, args=(procs,))\n",
    "\n",
    "# Step 4: Specify which process each thread runs in.\n",
    "# thread_0 runs in the process called 'p1'\n",
    "procs['p1'].threads = [thread_0]\n",
    "\n",
    "# Step 5: Start, join and terminate processes.\n",
    "for process in processes: process.start()\n",
    "for process in processes: process.join()\n",
    "for process in processes: process.terminate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of Multicore with NumPy Arrays\n",
    "This example illustrates the use of <b>StreamArray</b> which is a stream treated as a NumPy array with an arbitrarily large number of rows. Using <i>StreamArray</i> can be more efficient than using <i>Stream</i> for large computations. \n",
    "<br>\n",
    "<br>\n",
    "These examples are simple and small; however, in most applications each process function would convert an input stream to a <i>StreamArray</i> and carry out a lot computation as arrays before sending the results as output streams.\n",
    "<br>\n",
    "<br>\n",
    "The streams, sources, and process structure are similar to the previous two examples. The process functions differ in that the functions in this example use <i>StreamArray</i> whereas the earlier examples used <i>Stream</i>.\n",
    "<br>\n",
    "<br>\n",
    "You convert a Stream of numbers to a StreamArray of ints, floats, or doubles by calling the functions <b>dtype_int</b>, <b>dtype_float</b>, and <b>dtype_double</b> respectively.\n",
    "<br>\n",
    "<br>\n",
    "In this example, the agent functions <i>f</i> and <i>g</i> operate on StreamArrays of floats though the source function <i>h</i> generates a stream of int.\n",
    "![alt text](ExampleOfTwoNumpyAgents.jpg \"Example of Two Numpy Agents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from IoTPy.helper_functions.type import dtype_float\n",
    "\n",
    "def test_multicore_with_arrays():\n",
    "    # Step 0: Define agent functions, source threads \n",
    "    # and actuator threads (if any).\n",
    "\n",
    "    # Step 0.0: Define agent functions.\n",
    "\n",
    "    # f_numpy is the agent function for processor called 'p0'.\n",
    "    def f_numpy(in_streams, out_streams):\n",
    "        map_window(\n",
    "            np.mean, dtype_float(in_streams[0]), out_streams[0],\n",
    "            window_size=2, step_size=2)\n",
    "\n",
    "    # g_numpy is the agent function for processor called 'p1'.\n",
    "    def g_numpy(in_streams, out_streams):\n",
    "        t = StreamArray('t')\n",
    "        map_window(max, dtype_float(in_streams[0]), t, \n",
    "                   window_size=2, step_size=2)\n",
    "        print_stream(t)\n",
    "\n",
    "    # Step 0.1: Define source thread targets (if any).\n",
    "    def thread_target_numpy(procs):\n",
    "        for i in range(3):\n",
    "            extend_stream(procs, data=list(range(i*10, (i+1)*10)), \n",
    "                          stream_name='x')\n",
    "            # Sleep to simulate an external data source.\n",
    "            time.sleep(0.001)\n",
    "        # Terminate stream because this stream will not be extended.\n",
    "        terminate_stream(procs, stream_name='x')\n",
    "\n",
    "    # Step 1: multicore_specification of streams and processes.\n",
    "    # Specify Streams: list of pairs (stream_name, stream_type).\n",
    "    # Specify Processes: name, agent function, \n",
    "    #       lists of inputs and outputs, additional arguments.\n",
    "    multicore_specification = [\n",
    "        # Streams\n",
    "        [('x', 'i'), ('y', 'f')],\n",
    "        # Processes\n",
    "        [{'name': 'p0', 'agent': f_numpy, 'inputs':['x'], \n",
    "          'outputs': ['y'], 'sources': ['x']},\n",
    "         {'name': 'p1', 'agent': g_numpy, 'inputs': ['y']}]\n",
    "    ]\n",
    "\n",
    "    # Step 2: Create processes.\n",
    "    processes, procs = get_processes_and_procs(multicore_specification)\n",
    "\n",
    "    # Step 3: Create threads (if any)\n",
    "    thread_0 = threading.Thread(target=thread_target_numpy, args=(procs,))\n",
    "\n",
    "    # Step 4: Specify which process each thread runs in.\n",
    "    # thread_0 runs in the process called 'p1'\n",
    "    procs['p1'].threads = [thread_0]\n",
    "\n",
    "    # Step 5: Start, join and terminate processes.\n",
    "    for process in processes: process.start()\n",
    "    for process in processes: process.join()\n",
    "    for process in processes: process.terminate()\n",
    "\n",
    "test_multicore_with_arrays()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of Merging Streams from Multiple Processes\n",
    "This example shows a slightly more complex process structure. The example has four processes\n",
    "called <i>coordinator</i>, <i>sine</i>, <i>cosine</i>, and <i>tangent</i>. The <i>coordinator</i> generates a sequence of values that are sent to other processes which compute sines, cosines and tangents of these values and send the results back to the <i>coordinator</i>. The <i>coordinator</i> then computes the square of the error --- the difference between tangent and sine/cosine.\n",
    "<br>\n",
    "<br>\n",
    "This example gives names to agents. This is helpful in debugging because the error statements identify the agent that caused the error. We haven't given names to agents in some examples for brevity.\n",
    "![alt text](ExampleOfCoordinator.jpg \"Example of Coordinator\")\n",
    "\n",
    "### Process Structure\n",
    "<ol>\n",
    "    <li> A source function <i>h</i> extends stream <i>x</i> with a sequence of 10 values between 0.0 and pi. This source function executes in a thread in the process called <i>coordinator</i>. Stream <i>x</i> is an input for all processes.\n",
    "    </li> \n",
    "    <li> Agents <i>sine</i>, <i>cosine</i>, and <i>tangent</i> read stream <i>x</i> and output streams <i>sines</i>, <i>cosines</i>, and <i>tangents</i> respectively. These streams are inputs to process <i>coordinate</i>.\n",
    "    </li>\n",
    "<ol> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IoTPy.agent_types.merge import zip_map\n",
    "\n",
    "def example_merging_streams_from_multiple_processes():\n",
    "    # Step 0: Define agent functions, source threads \n",
    "    # and actuator threads (if any).\n",
    "\n",
    "    # Step 0.0: Define agent functions.\n",
    "    \n",
    "    # sine is the agent function for the process called 'sine'.\n",
    "    def sine(in_streams, out_streams):\n",
    "        map_element(np.sin, dtype_float(in_streams[0]), out_streams[0], \n",
    "                    name='sine')\n",
    "\n",
    "    # cosine is the agent function for the process called 'cosine'.\n",
    "    def cosine(in_streams, out_streams):\n",
    "        map_element(np.cos, dtype_float(in_streams[0]), out_streams[0], \n",
    "                    name='cosine')\n",
    "\n",
    "    # tangent is the agent function for the process called 'tangent'.\n",
    "    def tangent(in_streams, out_streams):\n",
    "        map_element(np.tan, dtype_float(in_streams[0]), out_streams[0], \n",
    "                    name='tangent')\n",
    "\n",
    "    # coordinate is the agent function for the process called 'coordinate'.\n",
    "    def coordinate(in_streams, out_streams):\n",
    "        x, sines, cosines, tangents = in_streams\n",
    "\n",
    "        def f(lst): return lst[0]/lst[1]\n",
    "\n",
    "        def g(lst):\n",
    "            error_squared= (lst[0] - lst[1])**2\n",
    "            return error_squared\n",
    "    \n",
    "        ratios = Stream('ratios')\n",
    "        errors = Stream('errors')\n",
    "        zip_map(f, [sines, cosines], ratios, name='sine / cosine')\n",
    "        zip_map(g, [ratios, tangents], errors, name='compute error')\n",
    "        print_stream(errors, 'error')\n",
    "\n",
    "    # # Step 0.1: Define source thread target (if any).\n",
    "    def source_thread_target(procs):\n",
    "        extend_stream(procs, data = np.linspace(0.0, np.pi, 10), stream_name='x')\n",
    "        terminate_stream(procs, stream_name='x')\n",
    "\n",
    "    # Step 1: multicore_specification of streams and processes.\n",
    "    # Specify Streams: list of pairs (stream_name, stream_type).\n",
    "    # Specify Processes: name, agent function, \n",
    "    #       lists of inputs and outputs and sources, additional arguments.\n",
    "    multicore_specification = [\n",
    "        # Streams\n",
    "        [('x', 'f'), ('sines', 'f'), ('cosines', 'f'), ('tangents', 'f')],\n",
    "        # Processes\n",
    "        [{'name': 'sine', 'agent': sine, 'inputs':['x'], 'outputs': ['sines']},\n",
    "         {'name': 'cosine', 'agent': cosine, 'inputs':['x'], 'outputs': ['cosines']},\n",
    "         {'name': 'tanget', 'agent': tangent, 'inputs':['x'], 'outputs': ['tangents']},\n",
    "         {'name': 'coordinator', 'agent': coordinate, 'inputs':['x', 'sines', 'cosines', 'tangents'],\n",
    "          'sources': ['x']}]\n",
    "    ]\n",
    "\n",
    "    # Step 2: Create processes.\n",
    "    processes, procs = get_processes_and_procs(multicore_specification)\n",
    "\n",
    "    # Step 3: Create threads (if any)\n",
    "    thread_0 = threading.Thread(target=source_thread_target, args=(procs,))\n",
    "\n",
    "    # Step 4: Specify which process each thread runs in.\n",
    "    # thread_0 runs in the process called 'coordinator'\n",
    "    procs['coordinator'].threads = [thread_0]\n",
    "\n",
    "    # Step 5: Start, join and terminate processes.\n",
    "    for process in processes: process.start()\n",
    "    for process in processes: process.join()\n",
    "    for process in processes: process.terminate()\n",
    "\n",
    "example_merging_streams_from_multiple_processes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Passing Data to and from Multiprocessing Blocks\n",
    "Non-IoTPy processes or threads can interact concurrently with IoTPy by extending input streams, getting data from queues fed by output streams, and by putting data into, and getting data from, multiprocessing blocks.\n",
    "![alt text](ExampleOfInteractionWithNonIoTPy.jpg \"Title\")\n",
    "This example illustrates how to pass data to a multiprocessing block and get data from the block. This example is the same as the previous one except that the variables <b>total</b> and <b>num</b> are passed to the multiprocessing block which returns updated values of these variables.\n",
    "<br>\n",
    "<br>\n",
    "total = multiprocessing.Value('f')\n",
    "<br>\n",
    "num = multiprocessing.Value('i')\n",
    "<br>\n",
    "<br>\n",
    "creates <i>total</i> a wrapper for a float, and <i>num</i> a wrapper for int. \n",
    "<br>\n",
    "<br>\n",
    "These variables can be passed to any collection of processes. In this example they are passed only to the process <i>coordinator</i>.\n",
    "These variables are assigned initial values from a computation that is not shown here. The multiprocessing block shown updates these values. For example, the value of <i>num</i> is 25 before the block is executed and 45 after it terminates.\n",
    "\n",
    "### Passing variables as keyword or positional arguments\n",
    "In this example, variables are passed to the process <i>coordinator</i> as keyword arguments.\n",
    "The keyword arguments are specified as a dict with the name of an argument (e.g. 'total') and its initial value (<i>total</i>).\n",
    "<br>\n",
    "<br>\n",
    "{'name': 'coordinator', 'agent': coordinate, 'inputs':['x', 'sines', 'cosines', 'tangents'],\n",
    "<br>\n",
    " 'sources': ['x'], 'source_functions':[sequence],\n",
    "<br>\n",
    "<b>'keyword_args'</b> : {'total' : total, 'num' : num},}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "\n",
    "def example_passing_data_to_multicore():\n",
    "    total = multiprocessing.Value('f')\n",
    "    num = multiprocessing.Value('i')\n",
    "    # Values computed from an earlier computation which is not shown.\n",
    "    # total and num are passed to the multiprocessing block.\n",
    "    total.value = 4.0e-13\n",
    "    num.value = 25\n",
    "\n",
    "    # Step 0: Define agent functions, source threads \n",
    "    # and actuator threads (if any).\n",
    "\n",
    "    # Step 0.0: Define agent functions.\n",
    "\n",
    "    # sine is the agent function for the process called  'sine'.\n",
    "    def sine(in_streams, out_streams):\n",
    "        map_element(np.sin, dtype_float(in_streams[0]), \n",
    "                    out_streams[0], name='sine')\n",
    "\n",
    "    # cosine is the agent function for the process called 'cosine'.\n",
    "    def cosine(in_streams, out_streams):\n",
    "        map_element(np.cos, dtype_float(in_streams[0]), out_streams[0], name='cosine')\n",
    "\n",
    "    # tangent is the agent function for the process called 'tangent'.\n",
    "    def tangent(in_streams, out_streams):\n",
    "        map_element(np.tan, dtype_float(in_streams[0]), \n",
    "                    out_streams[0], name='tangent')\n",
    "\n",
    "    # coordinate is the agent function for the process called 'coordinate'.\n",
    "    def coordinate(in_streams, out_streams, total, num):\n",
    "        x, sines, cosines, tangents = in_streams\n",
    "\n",
    "        def f(lst): return lst[0]/lst[1]\n",
    "\n",
    "        def g(lst):\n",
    "            error_squared= (lst[0] - lst[1])**2\n",
    "            return error_squared\n",
    "    \n",
    "        ratios = Stream('ratios')\n",
    "        errors = Stream('errors')\n",
    "        zip_map(f, [sines, cosines], ratios, name='sine / cosine')\n",
    "        zip_map(g, [ratios, tangents], errors, name='compute error')\n",
    "        print_stream(errors, 'error')\n",
    "\n",
    "    # Step 0.1: Define source thread target (if any).\n",
    "    def source_thread_target(procs):\n",
    "        extend_stream(procs, data=np.linspace(0.0, np.pi, 10), stream_name='x')\n",
    "        terminate_stream(procs, stream_name='x')\n",
    "\n",
    "    # Step 1: multicore_specification of streams and processes.\n",
    "    # Specify Streams: list of pairs (stream_name, stream_type).\n",
    "    # Specify Processes: name, agent function, \n",
    "    #       lists of inputs and outputs and sources, additional arguments.\n",
    "    multicore_specification = [\n",
    "        # Streams\n",
    "        [('x', 'f'), ('sines', 'f'), ('cosines', 'f'), ('tangents', 'f')],\n",
    "        # Processes\n",
    "        [{'name': 'sine', 'agent': sine, 'inputs':['x'], 'outputs': ['sines']},\n",
    "         {'name': 'cosine', 'agent': cosine, 'inputs':['x'], 'outputs': ['cosines']},\n",
    "         {'name': 'tanget', 'agent': tangent, 'inputs':['x'], 'outputs': ['tangents']},\n",
    "         {'name': 'coordinator', 'agent': coordinate, 'inputs':['x', 'sines', 'cosines', 'tangents'],\n",
    "          'sources': ['x'], 'keyword_args' : {'total' : total, 'num' : num}}]\n",
    "    ]\n",
    "\n",
    "    # Step 2: Create processes.\n",
    "    processes, procs = get_processes_and_procs(multicore_specification)\n",
    "\n",
    "    # Step 3: Create threads (if any)\n",
    "    thread_0 = threading.Thread(target=source_thread_target, args=(procs,))\n",
    "\n",
    "    # Step 4: Specify which process each thread runs in.\n",
    "    # thread_0 runs in the process called 'coordinator'\n",
    "    procs['coordinator'].threads = [thread_0]\n",
    "\n",
    "    # Step 5: Start, join and terminate processes.\n",
    "    for process in processes: process.start()\n",
    "    for process in processes: process.join()\n",
    "    for process in processes: process.terminate()\n",
    "\n",
    "example_passing_data_to_multicore()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actuators\n",
    "A multiprocessing block may need to interact asynchronously with some external device. To do so, the block puts data into a queue and uses threads responsible for interfacing between the queue and the device. This simple example illustrates the simplest actuator: a printer. Indeed printing can be done synchronously by the multiprocessing block. Printing doesn't need a queue to interface between it and the block. We use the printer in this example to illustrate the idea.\n",
    "<br>\n",
    "<br>\n",
    "Function <i>g</i> of process <i>p1</i> has an agent called 'copy_stream_s_to_queue_q' which  copies stream <i>s</i> to queue <i>q</i>. A thread, <b>my_thread</b> in <i>p1</i> prints values from the queue; this thread represents the thread that interfaces with an external actuator device. This thread is in addition to any source threads that may exist.\n",
    "<br>\n",
    "<br>\n",
    "Queue <i>q</i> is specified as an <b>output queue</b>. An output queue gets a special message <b>'_finished'</b> when the multiprocess block terminates.\n",
    "<br>\n",
    "<br>\n",
    "Threads (apart from source threads) and output queues are specified in <i>multicore_specifications</i>. See\n",
    "<br>\n",
    "<br>\n",
    "{'name': 'p1', 'agent': g, 'inputs': ['y'], \n",
    "<br>\n",
    " 'args': [q], <b>'output_queues'</b>: [q], <b>'threads'</b>: [my_thread]}\n",
    "<br>\n",
    "<br>\n",
    "The thread, <i>my_thread</i>, terminates when it receives a '_finished' message. We want this thread to terminate so that process <i>p1</i> terminates, and then the entire multiprocessing block can terminate as well.\n",
    "![alt text](ExamplesOfOutputQueue.jpg \"Title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "from IoTPy.agent_types.sink import stream_to_queue\n",
    "\n",
    "def example_output_thread_with_queue():\n",
    "    q = multiprocessing.Queue()\n",
    "\n",
    "    # Step 0: Define agent functions, source threads \n",
    "    # and actuator threads (if any).\n",
    "\n",
    "    # Step 0.0: Define agent functions.\n",
    "\n",
    "    # g is the agent function for the process called 'p1'.\n",
    "    def g(in_streams, out_streams, q):\n",
    "        s = Stream('s')\n",
    "        map_element(lambda v: v*2, in_streams[0], s)\n",
    "        stream_to_queue(s, q, name='copy_stream_s_to_queue_q')\n",
    "\n",
    "    # Step 0.1: Define source thread target (if any).\n",
    "    def source_thread_target(procs):\n",
    "        for i in range(3):\n",
    "            extend_stream(procs, data=list(range(i*2, (i+1)*2)), \n",
    "                          stream_name='x')\n",
    "            time.sleep(0.001)\n",
    "        terminate_stream(procs, stream_name='x')\n",
    "\n",
    "    # Define the actuator thread target. This thread target is\n",
    "    # used to create a thread (output) which is run in the process\n",
    "    # called 'p0'.\n",
    "    def get_data_from_output_queue(q):\n",
    "        while True:\n",
    "            v = q.get()\n",
    "            if v == '_finished': break\n",
    "            else: print ('q.get() = ', v)\n",
    "\n",
    "    multicore_specification = [\n",
    "        # Streams\n",
    "        [('x', 'i'), ('y', 'i')],\n",
    "        # Processes\n",
    "        [{'name': 'p0', 'agent': f, 'inputs':['x'], 'outputs': ['y'], 'sources': ['x']},\n",
    "         {'name': 'p1', 'agent': g, 'inputs': ['y'], \n",
    "          'args': [q], 'output_queues': [q]}]\n",
    "    ]\n",
    "\n",
    "    processes, procs = get_processes_and_procs(multicore_specification)\n",
    "    source_thread = threading.Thread(target=source_thread_target, args=(procs,))\n",
    "    output_thread = threading.Thread(target=get_data_from_output_queue, args=(q,))\n",
    "    procs['p0'].threads = [source_thread, output_thread]\n",
    "\n",
    "    for process in processes: process.start()\n",
    "    for process in processes: process.join()\n",
    "    for process in processes: process.terminate()\n",
    "\n",
    "example_output_thread_with_queue()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of Process Structure with Feedback\n",
    "The example shows a process structure with feedback. This example creates an echo from a spoken sound. (You can write more efficient and succinct code to compute echoes. The code in this example is here merely because it illustrates a concept.)\n",
    "![alt text](ExamplesOfFeedback.jpg \"Title\")\n",
    "<br>\n",
    "### Streams\n",
    "<ol>\n",
    "    <li><b>sound_made</b>: This is the sound made by a speaker in a large spherical space.</li>\n",
    "    <li><b>attenuated</b>: This is the sound made multiplied by an attenuation factor.</li>\n",
    "    <li><b>echo</b>: This is the echo of the sound made heard at the center of the room. The echo is a delay followed by an attenuation of the sound heard. </li>\n",
    "    <li><b>sound_heard</b>: This is the sound that is heard by the speaker. The heard sound is the sound made by the speaker plus the echo.</li>\n",
    "</ol>\n",
    "The equations that define the streams are:\n",
    "<ol>\n",
    "    <li>\n",
    "    <b>attentuated[n] = sound_heard[n]*attenuation</b>\n",
    "    </li>\n",
    "    <li>\n",
    "    <b>echo[n] = attentuated[n-delay]</b> for n > delay.\n",
    "    </li>\n",
    "    <li>\n",
    "    <b>sound_heard[n] = sound_made[n] + echo[n]</b> for n > delay.\n",
    "    </li>\n",
    "</ol>\n",
    "\n",
    "### Process Structure\n",
    "Process <i>p0</i> has a source which feeds one of its input streams <i>sound_made</i> with a stream of measurements obtained from a microphone. In this example, the stream is generated with numbers so that we can see how streams are processed.\n",
    "<br>\n",
    "<br>\n",
    "Process <i>p1</i> contains a single input stream which is the sound heard and a single output stream which is an attenuation of the sound heard. \n",
    "\n",
    "### Process Functions\n",
    "The function <i>f</i> of <i>p0</i> computes <i>echo</i> from <i>sound_made</i>. The first 4 , i.e., <b>delay</b>, units of the echo are empty (i.e. 0). \n",
    "<br>\n",
    "<b>map_element(lambda v: v, attenuated, echo)</b>\n",
    "<br>\n",
    "copies the attenuated stream to the echo stream; however, since the first 4 (i.e. delay) values of the echo stream are 0, the echo stream will consist of 4 zeroes followed by the attenuated stream.\n",
    "<br>\n",
    "<i>out_streams[0]</i> of process <i>p0</i> is <i>sound_heard</i>. Function <i>f</i> makes <i>sound_heard</i> the sum of the echo and the sound made.\n",
    "<br>\n",
    "The function <i>g</i> of process <i>p1</i> <i>p0</i> puts elements of its input stream (i.e. <i>sound_heard</i> on queue <i>q</i> and returns the elements multiplied by <i>attenuation</i>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IoTPy.agent_types.basics import *\n",
    "\n",
    "def example_echo_two_cores():\n",
    "    # This is the delay from when the made sound hits a\n",
    "    # reflecting surface.\n",
    "    delay = 6\n",
    "\n",
    "    # This is the attenuation of the reflected wave.\n",
    "    attenuation = 0.5\n",
    "\n",
    "    # The results are put in this queue. A thread reads this\n",
    "    # queue and feeds a speaker or headphone.\n",
    "    q = multiprocessing.Queue()\n",
    "\n",
    "    # ----------------------------------------------\n",
    "    # Step 0: Define agent functions, source threads \n",
    "    # and actuator threads (if any).\n",
    "\n",
    "    # Step 0.0: Define agent functions.\n",
    "    \n",
    "    # Agent function for process named 'p0'\n",
    "    # echo is a delay of zeroes followed by attenuated heard sound.\n",
    "    # out_streams[0], which is the same as sound_heard, is\n",
    "    # echo + sound_made\n",
    "    def f_echo(in_streams, out_streams, delay):\n",
    "        sound_made, attenuated = in_streams\n",
    "        echo = StreamArray('echo', dtype='float')\n",
    "        echo.extend(np.zeros(delay, dtype='float'))\n",
    "        map_element(lambda v: v, attenuated, echo)\n",
    "        # The zip_map output is the sound heard which is\n",
    "        # the sound heard plus the echo.\n",
    "        zip_map(sum, [sound_made, echo], out_streams[0])\n",
    "\n",
    "    # Agent function for process named 'p1'\n",
    "    # This process puts the sound heard into the output queue\n",
    "    # and returns an attenuated version of the sound_heard as \n",
    "    # its output stream.\n",
    "    def g_echo(in_streams, out_streams, attenuation, q):\n",
    "        def gg(v):\n",
    "            # v is the sound heard\n",
    "            q.put(v)\n",
    "            # v*attenuation is the echo\n",
    "            print ('in g_echo; v is ', v)\n",
    "            return v*attenuation\n",
    "        map_element(gg, in_streams[0], out_streams[0])\n",
    "\n",
    "    def source_thread_target(procs):\n",
    "        data=list(range(10))\n",
    "        extend_stream(procs, data=np.array(np.arange(10.0)), stream_name='sound_made')\n",
    "        time.sleep(0.0001)\n",
    "        extend_stream(procs, data=np.array([0.0]*10), stream_name='sound_made')\n",
    "        terminate_stream(procs, stream_name='sound_made')\n",
    "\n",
    "    # Thread that gets data from the output queue\n",
    "    # This thread is included in 'threads' in the specification.\n",
    "    # Thread target\n",
    "    def get_data_from_output_queue(q):\n",
    "        finished_getting_output = False\n",
    "        while not finished_getting_output:\n",
    "            v = q.get()\n",
    "            if v == '_finished': break\n",
    "            print ('heard sound = spoken + echo: ', v)\n",
    "\n",
    "    multicore_specification = [\n",
    "        # Streams\n",
    "        [('sound_made', 'f'), ('attenuated', 'f'), ('sound_heard', 'f')],\n",
    "        # Processes\n",
    "        [{'name': 'p0', 'agent': f_echo, 'inputs': ['sound_made', 'attenuated'], \n",
    "          'outputs': ['sound_heard'], 'keyword_args' : {'delay' : delay}, 'sources': ['sound_made']},\n",
    "         {'name': 'p1', 'agent': g_echo, 'inputs': ['sound_heard'], 'outputs': ['attenuated'],\n",
    "          'args': [attenuation, q], 'output_queues': [q] } ]]\n",
    "\n",
    "    processes, procs = get_processes_and_procs(multicore_specification)\n",
    "     \n",
    "    source_thread = threading.Thread(target=source_thread_target, args=(procs,))\n",
    "    output_thread = threading.Thread(target=get_data_from_output_queue, args=(q,))\n",
    "    procs['p0'].threads = [source_thread, output_thread]\n",
    "\n",
    "    for process in processes: process.start()\n",
    "    for process in processes: process.join()\n",
    "    for process in processes: process.terminate()\n",
    "\n",
    "example_echo_two_cores()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example source and actuator thread with single process\n",
    "This example is the same as the previous one except that the computation is carried out in a single process rather in two processes. The example illustrates an actuator thread and a source thread in the same process.\n",
    "![alt text](ExamplesOfSingleProcess.jpg \"Title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def example_echo_single_core():\n",
    "    # This is the delay from when the made sound hits a\n",
    "    # reflecting surface.\n",
    "    delay = 4\n",
    "\n",
    "    # This is the attenuation of the reflected wave.\n",
    "    attenuation = 0.5\n",
    "\n",
    "    # The results are put in this queue. A thread reads this\n",
    "    # queue and feeds a speaker or headphone.\n",
    "    q = multiprocessing.Queue()\n",
    "\n",
    "    # ----------------------------------------------\n",
    "    # Step 0: Define agent functions, source threads \n",
    "    # and actuator threads (if any).\n",
    "\n",
    "    # Step 0.0: Define agent functions.\n",
    "\n",
    "    # Agent function for process named 'p0'\n",
    "    # echo is a delay of zeroes followed by attenuated heard sound.\n",
    "    # out_streams[0], which is the same as sound_heard is\n",
    "    # echo + sound_made\n",
    "        \n",
    "    def f_echo(in_streams, out_streams, delay, attenuation, q):\n",
    "        echo = StreamArray('echo', dtype='float')\n",
    "        echo.extend(np.zeros(delay, dtype='float'))\n",
    "        #echo = Stream('echo', initial_value=[0]*delay)\n",
    "        #Note: sound_made = in_streams[0]\n",
    "        sound_heard = in_streams[0] + echo\n",
    "        map_element(lambda v: v*attenuation, sound_heard, echo)\n",
    "        stream_to_queue(sound_heard, q)\n",
    "\n",
    "    def source_thread_target(procs):\n",
    "        extend_stream(procs, data=list(range(10)), stream_name='sound_made')\n",
    "        time.sleep(0.0001)\n",
    "        extend_stream(procs=procs, data=[0]*10, stream_name='sound_made')\n",
    "        terminate_stream(procs, stream_name='sound_made')\n",
    "\n",
    "    # Thread that gets data from the output queue\n",
    "    # This thread is included in 'threads' in the specification.\n",
    "    # Thread target\n",
    "    def get_data_from_output_queue(q):\n",
    "        finished_getting_output = False\n",
    "        while not finished_getting_output:\n",
    "            v = q.get()\n",
    "            if v == '_finished': break\n",
    "            print ('heard sound = spoken + echo: ', v)\n",
    "\n",
    "    multicore_specification = [\n",
    "        # Streams\n",
    "        [('sound_made', 'f')],\n",
    "        # Processes\n",
    "        [{'name': 'p0', 'agent': f_echo, 'inputs': ['sound_made'],\n",
    "          'args' : [delay, attenuation, q], 'sources': ['sound_made'],'output_queues': [q]}]]\n",
    "\n",
    "    processes, procs = get_processes_and_procs(multicore_specification)\n",
    "     \n",
    "    source_thread = threading.Thread(target=source_thread_target, args=(procs,))\n",
    "    output_thread = threading.Thread(target=get_data_from_output_queue, args=(q,))\n",
    "    procs['p0'].threads = [source_thread, output_thread]\n",
    "\n",
    "    for process in processes: process.start()\n",
    "    for process in processes: process.join()\n",
    "    for process in processes: process.terminate()\n",
    "\n",
    "example_echo_single_core()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of a grid computation\n",
    "Grid computations are used in science, for example in computing the temperature of a metal plate. The grid is partitioned into regions with a process assigned to simulate each region. On the n-th step, each process reads the values of relevant parts of the grid and updates its own value.\n",
    "<br>\n",
    "<br>\n",
    "This example uses two copies of the grid; the two copies are <b>even</b> and <b>odd</b>. \n",
    "<ol>\n",
    "    <li>On <b>even</b> steps (i.e., steps 0, 2, 4,..) the <i>j</i>-th\n",
    "        proces <b>reads</b> the <i>even</i> grid and <b>writes</b> the\n",
    "        <i>j</i>-th element of the <i>odd</i> grid. </li>\n",
    "    <li>On <b>odd</b> steps, the <i>j</i>-th proces <b>reads</b> the\n",
    "        <i>odd</i> grid and <b>writes</b> the <i>j</i>-th element of the \n",
    "        <i>even</i> grid. </li>\n",
    "</ol>\n",
    "So, each portion of the grid is modified by only one process. And no process reads a value while it is modified.\n",
    "\n",
    "### The example problem\n",
    "A linear metal bar of length <i>N</i> is partitioned into a grid of <i>N</i> continuous regions. Grid 0 is kept at a constant temperature of 0 degrees while grid <i>N-1</i> is kept at a constant temperature of <i>N-1</i> degrees. Initially, the temperature at intermediate grid points is arbitrary; in the code below, the temperature at grid point <i>i</i> exceeds <i>i</i> by <i>DELTA</i>.\n",
    "<br>\n",
    "<br>\n",
    "Let <b>TEMP[i][k]</b> be the temperature of the <i>i</i>-th region on step <i>k</i>. Then, for all <i>k</i>:\n",
    "<ol>\n",
    "    <li>TEMP[0][k] = 0 </li>\n",
    "    <li>TEMP[N-1][k] = N-1 </li>\n",
    "    <li>TEMP[i][k] = (TEMP[i-1][k] + TEMP[i][k] + TEMP[i+1][k])/3 i in [1, ..,N-2] </li>\n",
    "</ol>\n",
    "\n",
    "\n",
    "### Processes\n",
    "The computation uses <i>N-2</i> processes. The <i>i</i>-th process is called 'grid_i' and is responsible for simulating the <i>i</i>-th region.\n",
    "<br>\n",
    "Each process takes the <i>k + 1</i>-th step after it has finished the <i>k</i>-th step and it has determined that its neighbors have also finished the <i>k</i>-th step.\n",
    "<br>\n",
    "\n",
    "\n",
    "### Streams\n",
    "The system has one stream, <b>s_i</b> for the <i>i</i>-th process. This stream contains the elements [0, 1, .. , k] after the <i>i</i>-th process has completed <i>k</i>-th steps.\n",
    "<br>\n",
    "Process <i>grid_i</i> outputs stream <i>s_i</i> and inputs streams from its neighboring processes which are <i>grid_(i-1)</i> if <i>i</i> exceeds 1 and <i>grid_(i+1)</i> if <i>i</i> is less than <i>N-1</i>.\n",
    "\n",
    "### Process Structure\n",
    "The process structure is linear with each process getting input streams from each of its neighbors and sending its output stream to all its neighbors.\n",
    "![alt text](ExamplesOfGrid.jpg \"Title\")\n",
    "\n",
    "### Process Function\n",
    "The process begins by sending 0 on its output stream to indicate that it has finished its 0-th step.\n",
    "<br>\n",
    "<br>\n",
    "The <i>k</i>-th value of <i>in_streams[j]</i> is <i>k</i> when the <i>j</i>-th neighboring process has completed its <i>k</i>-th step.\n",
    "<br>\n",
    "<br>\n",
    "<b>synch_stream</b> is an internal stream of the process. The <i>k</i>-th element of this stream is <i>k</i> after all neighboring processes have completed their <i>k</i>-th step.\n",
    "<br>\n",
    "<br>\n",
    "The zip_map function <i>r</i> operates on a list with one element from each neighbor. All the elements of the list will be <i>k</i> on the <i>k</i>-th step. The zip_map function returns <i>k</i> which is any element of the list. In this example it returns the 0-th element.\n",
    "<br>\n",
    "<br>\n",
    "Thus the zip_map function acts as a synchronizer. It waits until all neighbors have completed the <i>k</i>-step and then it outputs <i>k</i>.\n",
    "<br>\n",
    "<br>\n",
    "Function <i>g</i> is called for the <i>k</i>-th time when this process and all its neighbors have completed <i>k - 1</i> steps. Function <i>g</i> does the grid computation. Function <i>r</i> and the zip_map agent are used merely for synchronizing.\n",
    "### run()\n",
    "Function <i>f</i> calls <b>run</b> after it has declared all its agents. Without calling run() the function will take no action.\n",
    "<br>\n",
    "<br>\n",
    "Note that when using external source threads, you should not call <i>run</i> because the source threads are responsible for starting and stopping the main computational thread. This example has no source threads so you must call <i>run</i> to start the system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IoTPy.core.stream import _no_value\n",
    "def test_grid():\n",
    "    # N is the size of the grid\n",
    "    N = 5\n",
    "    # M is the number of steps of execution.\n",
    "    M = 5\n",
    "    # DELTA is the deviation from the final solution.\n",
    "    DELTA = 0.01\n",
    "    # even, odd are the grids that will be returned\n",
    "    # by this computation\n",
    "    even = multiprocessing.Array('f', N)\n",
    "    odd = multiprocessing.Array('f', N)\n",
    "    # Set up initial values of the grid.\n",
    "    for i in range(1, N-1):\n",
    "        even[i] = i + DELTA\n",
    "    even[N-1] = N-1\n",
    "    odd[N-1] = N-1\n",
    "        \n",
    "    def f(in_streams, out_streams, index, even, odd):\n",
    "        def g(v):\n",
    "            if (0 < index) and (index < N-1):\n",
    "                if v%2 == 0:\n",
    "                    odd[index] = (even[index-1] + even[index] + even[index+1])/3.0\n",
    "                else:\n",
    "                    even[index] = (odd[index-1] + odd[index] + odd[index+1])/3.0\n",
    "            return v+1\n",
    "\n",
    "        def r(lst, state):\n",
    "            if state < M:\n",
    "                return lst[0], state+1\n",
    "            else:\n",
    "                return _no_value, state\n",
    "        for out_stream in out_streams: out_stream.extend([0])\n",
    "        synch_stream = Stream('synch_stream')\n",
    "        zip_map(r, in_streams, synch_stream, state=0, name='zip_map_'+str(index))\n",
    "        map_element(g, synch_stream, out_streams[0], name='grid'+str(index))\n",
    "        run()\n",
    "\n",
    "    multicore_specification = [\n",
    "        # Streams\n",
    "        [('s_'+str(index), 'i') for index in range(1, N-1)],\n",
    "        # Processes\n",
    "        [{'name': 'grid_'+str(index), 'agent': f, \n",
    "          'inputs':['s_'+str(index+1), 's_'+str(index-1)], \n",
    "          'outputs':['s_'+str(index)], \n",
    "          'args': [index, even, odd]} for index in range(2, N-2)] + \\\n",
    "        [{'name': 'grid_'+str(1), 'agent': f, \n",
    "          'inputs':['s_'+str(2)], 'outputs':['s_'+str(1)], \n",
    "          'args': [1, even, odd]}] + \\\n",
    "        [{'name': 'grid_'+str(N-2), 'agent': f, \n",
    "          'inputs':['s_'+str(N-3)], 'outputs':['s_'+str(N-2)], \n",
    "          'args': [N-2, even, odd]}]\n",
    "    ]\n",
    "\n",
    "    # Execute processes (after including your own non IoTPy processes)\n",
    "    processes = get_processes(multicore_specification)\n",
    "    for process in processes: process.start()\n",
    "    for process in processes: process.join()\n",
    "    for process in processes: process.terminate()\n",
    "\n",
    "    print ('Grid after ', M, ' steps is: ')\n",
    "    if M%2 == 0:\n",
    "        print (even[:])\n",
    "    else:\n",
    "        print (odd[:])\n",
    "\n",
    "test_grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Counting Elements in Streams\n",
    "The next example uses algorithms to count elements in streams (see IoTPy/examples/Counting). This example uses a Bloom Filter and a count-min-sketch algorithm. The data stream consists of pairs where a pair is either ('add', object) or ('check', object). The pair ('add', z) in the input stream states that object z was added to the data stream. The pair ('check', z) in the input stream is a command to check whether z was added earlier.\n",
    "<br>\n",
    "![alt text](CountingAlgorithms.jpg \"Counting Elements in Streams\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from examples.Counting.bloom_filter import bloom_filter_stream\n",
    "from examples.Counting.bloom_filter import BloomFilter\n",
    "from examples.Counting.count_min_sketch import count_min_sketch_stream\n",
    "from examples.Counting.count_min_sketch import CountMinSketch\n",
    "from IoTPy.agent_types.merge import merge_asynch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_multiprocessing_counting_algorithms():\n",
    "    # ----------------------------------------------\n",
    "    # Step 0: Define agent functions, source threads \n",
    "    # and actuator threads (if any).\n",
    "\n",
    "    # Step 0.0: Define agents\n",
    "    def bloom_filter_agent(in_streams, out_streams):\n",
    "        bloom_filter = BloomFilter(\n",
    "            est_elements=1000, false_positive_rate=0.05)\n",
    "        bloom_filter_stream(in_streams[0], out_streams[0], \n",
    "                            bloom_filter=bloom_filter)\n",
    "\n",
    "    def count_min_sketch_agent(in_streams, out_streams):\n",
    "        count_min_sketch = CountMinSketch(width=1000, depth=20)\n",
    "        count_min_sketch_stream(in_streams[0], out_streams[0],\n",
    "                                count_min_sketch=count_min_sketch)\n",
    "\n",
    "    def merge_agent(in_streams, out_streams):\n",
    "        s = Stream('print stream')\n",
    "        def g(pair):\n",
    "            index, value = pair\n",
    "            if index == 0:\n",
    "                print ('bloom_filter. value: ', value)\n",
    "            else:\n",
    "                print ('count_min_sketch. value: ', value)\n",
    "        merge_asynch(g, in_streams, s)\n",
    "\n",
    "    # Step 0.1: Define source thread target (if any).\n",
    "    def source_thread_target(procs):\n",
    "        data=[('add', 'a'), ('add', 'b'), ('add', 'a'),\n",
    "              ('check', 'c'), ('add', 'd'), ('check','a')]\n",
    "        extend_stream(procs, data, stream_name='data')\n",
    "        time.sleep(0.001)\n",
    "        data=[('add', 'c'), ('check', 'b'), ('check', 'a'),\n",
    "              ('check', 'c'), ('check', 'e'), ('add', 'a')]\n",
    "        extend_stream(procs, data, stream_name='data')\n",
    "\n",
    "        terminate_stream(procs, stream_name='data')\n",
    "    \n",
    "    # Step 1: multicore_specification of streams and processes.\n",
    "    # Specify Streams: list of pairs (stream_name, stream_type).\n",
    "    # Specify Processes: name, agent function, \n",
    "    #       lists of inputs and outputs and sources, additional arguments.\n",
    "    multicore_specification = [\n",
    "        # Streams\n",
    "        [('data', 'x'), ('bloom_results', 'x'),\n",
    "         ('count_min_sketch_results', 'x')],\n",
    "        # Processes\n",
    "        [{'name': 'bloom_filter_process', 'agent': bloom_filter_agent, \n",
    "          'inputs':['data'], 'outputs': ['bloom_results'],\n",
    "          'sources': ['data']},\n",
    "         {'name': 'count_min_sketch_process', 'agent': count_min_sketch_agent, \n",
    "          'inputs':['data'], 'outputs': ['count_min_sketch_results']},\n",
    "         {'name': 'merge_process', 'agent': merge_agent,\n",
    "          'inputs': ['bloom_results', 'count_min_sketch_results']}\n",
    "        ]]\n",
    "\n",
    "    # Step 2: Create processes.\n",
    "    processes, procs = get_processes_and_procs(multicore_specification)\n",
    "\n",
    "    # Step 3: Create threads (if any)\n",
    "    thread_0 = threading.Thread(target=source_thread_target, args=(procs,))\n",
    "\n",
    "    # Step 4: Specify which process each thread runs in.\n",
    "    # thread_0 runs in the process called 'coordinator'\n",
    "    procs['bloom_filter_process'].threads = [thread_0]\n",
    "\n",
    "    # Step 5: Start, join and terminate processes.\n",
    "    for process in processes: process.start()\n",
    "    for process in processes: process.join()\n",
    "    for process in processes: process.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_multiprocessing_counting_algorithms()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
